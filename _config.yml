repository: rohanredtj/modern-resume-theme


favicon: images/favicon.ico


version: 2


name: Rohan Rathore
# title: Data Engineer | Bengaluru, India
title: Portfolio
# phone_title: Contact 
# phone: rohan.rathore93@gmail.com
email_title: Location
email: Bangalore, India


darkmode: never


# twitter_username: rohanredtj
github_username:  rohanredtj
# linkedin_username: rohanredtj
# instagram_username: rohanredtj


additional_links:
- title: Hire Rohan
  icon: fas fa-briefcase
  url: https://www.upwork.com/freelancers/~01ee871ca78c1a805c

google_analytics: "G-F7XR48JK4K"
# gtm: "GTM-0000000"
# gtag: "UA-00000000-0"

about_profile_image: images/profile.jpg
about_content: |

  ## **Expertise**
  <blockquote><span class="block-secondary">Data Engineering</span> <span class="block-secondary">Data Analysis</span> <span class="block-secondary">Data Warehousing</span> <span class="block-secondary">ETL</span> <span class="block-secondary">Big Data</span> <span class="block-secondary">Cloud Platforms</span> <span class="block-secondary">Data Modeling</span> <span class="block-secondary">Database Design</span> <span class="block-secondary">Data Pipeline Architecture</span> <span class="block-secondary">Version Control</span> <span class="block-secondary">Containerization</span></blockquote>
  
  ## **Project Categories**
  [Data Engineering](#data-engineering-projects), [Data Science](#data-science-projects), [Data Analytics](#data-analytics-projects), [Software Engineering](#software-engineering-projects), [Other](#other-projects)
  <br><br> 
  
  ## **Bio**
  Rohan is a data professional with 7 years of experience, two master's degrees, and a proven track record of working with distributed global teams. His expertise spans the entire data lifecycle, from data engineering and analytics to visualization and machine learning, allowing him to quickly adapt to new technologies and methodologies. Rohan's international exposure, diverse skill set, and eagerness to learn make him well-equipped to tackle complex data challenges and drive impactful solutions in fast-paced environments.
  <br><br> 

  ## **Experience**
  <blockquote><span class="block-secondary">Python - 6 years</span> <span class="block-secondary">Predictive Modeling - 6 years</span> <span class="block-secondary">SQL - 5 years</span> <span class="block-secondary">BigQuery - 3 years</span> <span class="block-secondary">Data Modelling - 3 years</span> <span class="block-secondary">Keras - 3 years</span> <span class="block-secondary">Django - 2 years</span> <span class="block-secondary">Amazon Web Services (AWS) - 2 years</span> <span class="block-secondary">PySpark - 2 years</span> <span class="block-secondary">DBT - 2 years</span> <span class="block-secondary">Docker - 1 years</span></blockquote>

  ## **Education**
  - Master of Science in Business Consulting, Furtwangen University, Germany ([Master Thesis](https://drive.google.com/file/d/13tQT1Bm3yGynGzH_6EMOoWVyrYhkPpH_))
  - Master of Science in Big Data Analytics & AI, Novosibirsk State University, Russia ([Master Thesis](https://link.springer.com/chapter/10.1007/978-981-16-5747-4_73))
  - Bachelor of Technology in Engineering Physics, Delhi Technological University, India
  <br><br> 

  ## **Certifications**
  - AWS Certified Data Engineer Associate ([Credly](https://www.credly.com/badges/70605561-9c5a-4d60-9f5e-804842954511))
  - Databricks Certified Data Engineer Associate ([Credentials Databricks](https://credentials.databricks.com/d1321b6b-9d2d-423f-850f-932ed0945cf7))
  - Dell EMC Data Science Assiociate ([Certmetrics NCB172QTLEFQQG55](https://www.certmetrics.com/dell/public/verification.aspx))
  <br><br> 

  ## **Skills**
  - **Libraries/APIs** - Pandas, NumPy, Scikit-learn, Apache Spark, Django
  - **Tools** - DBT, Docker, Apache Airflow
  - **Languages** - Python, SQL, R
  - **Paradigms** - ETL/ELT, Data Modeling, Data Warehousing, Big Data Processing
  - **Platforms** - MySQL, PostgreSQL, Amazon Web Services (AWS), Google Cloud Platform (GCP)
  - **Storage** - Amazon Redshift, Google BigQuery, Snowflake
  - **Other** - Data Pipeline Design, Data Quality Management, Data Analytics, Machine Learning
  <br><br>  

  ## **Preferred Environment**
  Visual Studio Code (VS Code), Amazon Web Services (AWS), Google Colab, MacOS


content:

  - title: Data Engineering Projects
    layout: list
    content:

      - layout: left #pid-52/1-1 | AWS-Powered Zillow Data Pipeline for Real Estate Analytics
        title: AWS-Powered Zillow Data Pipeline for Real Estate Analytics
        link: https://github.com/rohanredtj/aws-zillow-pipeline
        link_text: Proprietary Work (Sample Code ðŸ”—)  
        
        description: |     
          
          Engineered a data pipeline using medallion architecture for <mark>Zillow data</mark>, processing 1GB of daily scraped CSV files from AWS S3. Implemented <mark>data cleaning</mark> and standardization for 180 columns, storing results in Parquet format with Hive partitioning. Deployed as an AWS Lambda function with <mark>scheduled execution</mark> via CloudWatch, optimized for 3GB RAM allocation. <a href="https://drive.google.com/file/d/1rL68kHLu2Z5LXJMa2lstjNVX4ScQE-Vm" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** AWS S3, AWS Lambda, AWS CloudWatch, AWS CLI, Python, Pandas, PyArrow, CSV, Parquet, Hive partitioning

          ---

      - layout: left #pid-59/1-2 | Wiktionary Abbreviation Extractor for Legal Documents
        title: Wiktionary Abbreviation Extractor for Legal Documents
        link: https://github.com/rohanredtj/wiktionary-abbreviation-extractor
        link_text: Proprietary Work (Sample Code ðŸ”—)
        
        description: |
          
          Developed a sophisticated tool to extract and analyze abbreviations from <mark>Wiktionary dumps</mark>. The project involved <mark>parsing</mark> complex data structures, implementing custom algorithms for <mark>abbreviation detection</mark>, and handling various <mark>edge cases</mark> to ensure comprehensive coverage of linguistic variations. <a href="https://drive.google.com/file/d/11qORN-eejKRDXU4gUtZ9K6gReftltyUx" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XML processing libraries, regular expressions, data structures, version control (Git), shell scripting

          ---

      - layout: left #pid-15/1-3 | PySpark-Based Oil Price Prediction Model
        title: PySpark-Based Oil Price Prediction Model
        link: /#
        link_text: Proprietary Work
        
        description: |     
          
          Developed a sophisticated <mark>machine learning model</mark> using PySpark to <mark>predict oil prices</mark> based on comprehensive oil field data. This project leveraged big data technologies to process and <mark>analyze</mark> large-scale datasets, enhancing decision-making capabilities in the energy sector. The model incorporated various predictive techniques, including Facebook Prophet, and was <mark>deployed</mark> on AWS infrastructure for scalable performance and real-time insights. <a href="https://drive.google.com/file/d/10Iw-aw1UkWZfd7xZuEdnhKuP0u_ppZkr" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** PySpark, AWS EC2 (r5.2xlarge instances), Jupyter Notebook, Facebook Prophet, Scikit-learn, Apache Superset, AWS S3, SSH, Python

          ---

      - layout: left #pid-10/1-4 | Database Migration from Snowflake to PostgreSQL
        title: Database Migration from Snowflake to PostgreSQL
        link: https://github.com/rohanredtj/snowflake-to-postgres
        link_text: Project Code ðŸ”— 

        description: |     
          
          Developed a robust Python script to <mark>automate</mark> the process of <mark>migrating data</mark> from Snowflake to PostgreSQL. This tool ensures <mark>efficient</mark> and error-free data transfer between disparate database systems. It handles schema creation, table synchronization, and large-scale data movement with <mark>built-in error handling</mark>. The script also generates timestamped schemas for version control and easy rollback if needed. <a href="https://drive.google.com/file/d/11jFpgXil8EomlGrV_S6AAaZOt38fjC0b" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, SQLAlchemy, Pandas, Snowflake, PostgreSQL, SQL

          ---

      - layout: left #pid-62/1-4.5 | Google Search Console Data Extraction and BigQuery Integration
        title: Google Search Console Data Extraction and BigQuery Integration
        link: /#
        link_text: Proprietary Work

        description: |     
          
          Developed a Python-based tool to automate the <mark>extraction</mark> of Google Search Console (GSC) data and seamlessly <mark>integrate</mark> it with Google BigQuery (GBQ). This project streamlines the process of collecting and storing website <mark>performance metrics</mark>, enabling efficient data analysis and reporting. The tool supports <mark>customizable</mark> date ranges and multiple GSC properties, making it a versatile solution for SEO professionals and web analysts. <a href="https://drive.google.com/file/d/1O2dVPk4oj1ktw4yvvUveOq-KsOvnaLjd" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Google Search Console API, Google Cloud Platform, BigQuery, OAuth 2.0

          ---

      - layout: left #pid-8/1-5 | Automated Name Parsing for Healthcare Provider Lists
        title: Automated Name Parsing for Healthcare Provider Lists
        link: https://colab.research.google.com/drive/1aG3_g9X8F21TmTy_DnFSk-ljSRgPDQas?usp=drive_link
        link_text: Project Code ðŸ”— 
        
        description: |     
          
          Engineered a sophisticated Python-based system utilizing OpenAI to automate the <mark>extraction and parsing</mark> of healthcare provider information from diverse state-specific files. The system adeptly handles multiple file formats including PDF, Excel, and CSV, processing data from over <mark>10 different states</mark>. It manages complex variations in data structure, ensuring clean and accurate output for <mark>internal compliance</mark> and monitoring use. <a href="https://drive.google.com/file/d/10jpIEh0clB5KAGy05o_ADhV5tH-ZwWlV" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, OpenAI API, CSV handling libraries, Time management and logging tools

          ---

      - layout: left #pid-22/1-6 | Web Scraping Forbes Russia Top 200 Private Companies
        title: Web Scraping Forbes Russia Top 200 Private Companies
        link: https://colab.research.google.com/drive/1TJsT8sICYtkmeikV2H1kojG_aubV--4S?usp=sharing
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed a Python script to <mark>extract</mark> and structure data from <mark>Forbes Russia's</mark> list of top 200 private companies. The project involved web scraping techniques to gather <mark>detailed information</mark> including company rankings, names, financial data, industry sectors, management details, and geographical information. The extracted data was then organized into a comprehensive <mark>dataset</mark>, enabling in-depth analysis of Russia's leading private businesses. <a href="https://drive.google.com/file/d/1HYqJTY0_iO6vJimLq-FhVoSCaKSPOObe" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, BeautifulSoup, Pandas, NumPy, Requests, tqdm

      - layout: left #pid-31/1-7 | Anime Season Scraper Web Scraping Tool for MyAnimeList
        title: Anime Season Scraper Web Scraping Tool for MyAnimeList
        link: https://colab.research.google.com/drive/1gOYiXsQ7g-83GPFfpBjDfiqex_X1jHuF?usp=sharing
        link_text: Project Code ðŸ”—
        
        description: |     
          
          This project developed a web <mark>scraping</mark> tool to collect seasonal <mark>anime data</mark> from MyAnimeList. The script uses the MyAnimeList API to fetch information about anime releases for specified years and seasons. It then processes and organizes this data into a <mark>structured format</mark> using Pandas, saving the results as a CSV file for further analysis or use in other applications. <a href="https://drive.google.com/file/d/15qBzkr_Z3m0hdmlWneWu5yPtdq2niXy1" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Pandas, Requests, MyAnimeList API


  - title: Data Science Projects
    layout: list
    content:

      - layout: left #pid-12/2-1 | System Cancel Rate Prediction Model
        title: System Cancel Rate Prediction Model
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a machine learning model to accurately <mark>predict</mark> the system cancel rate for new jobs using pre-defined features. This model significantly <mark>improves</mark> customer lifetime value <mark>(LTV)</mark> predictions, enabling more efficient <mark>paid marketing</mark> campaigns and optimizing cleaner acquisition strategies. The project directly impacts business growth and operational efficiency. <a href="https://drive.google.com/file/d/1xg6tEgERrGU0m7Q50_xosdY3AL0U-c0G" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Machine Learning, Keras, Optuna, Data Analysis, Feature Engineering, Data Visualization

          ---

      - layout: left #pid-1/2-2 | YouTube Insights Analysis for Channel Performance
        title: YouTube Insights Analysis for Channel Performance
        link: https://colab.research.google.com/drive/1QWBifUwjdk7RVRA_-wHO2j9lEcIQlLq9
        link_text: Project Code ðŸ”—
        
        description: |     
          
          Conducted comprehensive <mark>data analysis</mark> on global YouTube statistics to uncover <mark>success factors</mark> for top channels. Employed <mark>machine learning</mark> techniques, including Random Forest Classifier, to identify key performance indicators. <mark>Visualized</mark> insights through <mark>geospatial</mark> analysis using GeoPandas. Explored correlations between channel metrics, subscriber growth, and earnings. Analyzed <mark>popular content</mark> categories and regional influencers' global impact. Developed <mark>actionable insights</mark> for content creators to optimize channel performance. <a href="https://drive.google.com/file/d/1eptYghvHy2rS7Oeq12cV8TaUHCjHdW6d" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>

          **Technologies:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, GeoPandas, Google Colab

          ---

      - layout: left #pid-9/2-3 | PDF Q&A Bestie - LLM RAG
        title: PDF Q&A Bestie - LLM RAG
        link: https://github.com/rohanredtj/QnA-Bestie-On-PDF
        link_text: Project Code ðŸ”—
        
        description: |
          
          PDF Q&A Bestie is an innovative app that enables users to <mark>upload PDF</mark> files and <mark>ask questions</mark> about their content. Powered by the <mark>Llama2</mark> AI model, it provides <mark>accurate answers</mark> extracted directly from the uploaded documents. This project leverages Replicate API to offer a computationally efficient solution with a free quota, making advanced AI capabilities accessible to users. <a href="https://drive.google.com/file/d/1D9mFPPEaznibyRoe3mmxQ7M5r9gDq1_G" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Llama2, Replicate API, Langchain, Pinecone, Streamlit, Python, Hugging Face Embeddings, PyPDF Loader

          ---

      - layout: left #pid-61/2-4 | Data Science Consulting for Real Estate
        title: Data Science Consulting for Real Estate
        link: https://www.kaggle.com/code/rohankaggler/property-price-prediction
        link_text: Project Code ðŸ”—
        
        description: |
          
          Conducted data analysis and <mark>business consulting</mark> for client's portfolio companies. Analyzed UK housing prices to provide actionable insights and propose advanced <mark>analytics strategies</mark>. Performed descriptive, exploratory, and <mark>predictive analyses</mark> to enhance business operations and decision-making. Delivered comprehensive presentations to company executives, focusing on <mark>data-driven</mark> solutions and value extraction from available datasets. <a href="https://drive.google.com/file/d/1iktbuAjz3H3LJmkt1FlJa0TXBgpk1m4p" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** R, Data Visualization, Statistical Analysis, Geospatial Analysis, Large Dataset, Kaggle Notebook

          ---

      - layout: left #pid-19/2-5 | Semantic Keyword Clustering Tool for Adwords
        title: Semantic Keyword Clustering Tool for Adwords
        link: https://github.com/rohanredtj/semantic-keyword-clustering
        link_text: Proprietary Work (Sample Code ðŸ”—)
        
        description: |
          
          Python-based tool for semantic keyword <mark>clustering</mark> using natural language processing techniques. This tool processes <mark>large volumes</mark> of keywords, performs text cleaning, and groups semantically similar terms into clusters. It utilizes <mark>sentence transformers</mark> for generating embeddings and implements community detection algorithms for creating meaningful keyword groupings, <mark>enhancing SEO</mark> and content strategy efforts. <a href="https://drive.google.com/file/d/1IpvgH6Cpj21PHmRJPagHoMq1o2Gulpwt" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Pandas, Sentence Transformers, NLTK, Scikit-learn

          ---

      - layout: left #pid-21/2-6 | Facebook Ad Bid Multiplier Optimization
        title: Facebook Ad Bid Multiplier Optimization
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed an algorithm to <mark>optimize</mark> Facebook's Bid Multiplier feature for <mark>targeted advertising</mark>. The project involved analyzing ~20,000 customer data points to create an <mark>efficient bid</mark> configuration based on demographic factors like age, gender, and device platform. The goal was to maximize 12-month customer <mark>Lifetime Value (LTV)</mark> while minimizing ad spend, resulting in <mark>improved</mark> Return on Ad Spend (ROAS). <a href="https://drive.google.com/file/d/12j8GksruKwaXp6Qt_hb-p_ME3QlURdrd" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, NumPy, Pandas, SciPy, Machine Learning, Data Analysis, Data Visualization

          ---

      - layout: left #pid-40/2-7 | Churn Prediction Model using XGBoost for Zenefits
        title: Churn Prediction Model using XGBoost for Zenefits
        link: https://colab.research.google.com/drive/1iJuzr62APaozFEF_WV_12WofcRqQ1r1r
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed a machine learning model to <mark>predict</mark> customer <mark>churn</mark> using XGBoost, an advanced gradient boosting algorithm. Achieved <mark>high accuracy</mark> and AUC scores through feature engineering and hyperparameter tuning. Implemented cross-validation for model optimization. This project enhanced the company's ability to proactively <mark>retain customers</mark> and improve business outcomes. <a href="https://drive.google.com/file/d/1d1wc_LWn1MUnRFg61mEaVyoJkrSmm8ba" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XGBoost, Pandas, NumPy, Scikit-learn, Matplotlib

          ---

      - layout: left #pid-18/2-8 | Product Recommendation System with LightGBM and Optuna
        title: Product Recommendation System with LightGBM and Optuna
        link: https://github.com/rohanredtj/product-recommendation-lightgbm
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed an advanced product recommendation system using machine learning techniques. The project involved data preprocessing, <mark>feature engineering</mark>, and model optimization to predict customer purchases. Implemented cross-validation for <mark>robust evaluation</mark> and utilized Optuna for hyperparameter tuning. The system aims to enhance <mark>sales predictions</mark> and improve <mark>customer targeting</mark> for a more efficient sales strategy. <a href="https://drive.google.com/file/d/1sLJ8FKL913tpiqgpQrc3Da4qPEQR_s85" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, pandas, scikit-learn, LightGBM, Optuna, NumPy, Tmux

          ---

      - layout: left #pid-14/2-9 | Predictive Model for Recruitment Time Estimation
        title: Predictive Model for Recruitment Time Estimation
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed an advanced machine learning model to <mark>predict</mark> recruitment <mark>fill times</mark> for job postings. The project involved data preprocessing, feature engineering, and implementing multiple XGBoost models for different <mark>pay structures</mark>. The final model significantly <mark>outperformed</mark> the baseline, enabling data-driven hiring strategies and significantly enhancing workforce planning efficiency. <a href="https://drive.google.com/file/d/1XHsm98nSaCGYXdwePMqVfTDJpJkEHwxP" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XGBoost, Keras-TensorFlow, Feature Engineering, RMSE, Time Series Analysis

      - layout: left #pid-26/2-10 | Dialogflow Based Intelligent Virtual Assistant Chatbot
        title: Dialogflow Based Intelligent Virtual Assistant Chatbot
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a <mark>chatbot</mark> to provide instant responses to prospective applicants' queries about an educational program. The chatbot automates <mark>FAQ handling</mark>, enhances user satisfaction, and streamlines communication across multiple platforms, including the institution's website and social media channels. It features intent recognition, multi-language support, and <mark>seamless integration</mark> with existing systems. The solution significantly reduces response times and improves <mark>information accessibility</mark> for potential students. <a href="https://drive.google.com/file/d/1r3fIrhY_QVmVZgnqBHcEWbVx7SoCg2az" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Dialogflow, Python, HTTPS Protocol, Social Media APIs

      - layout: left #pid-17/2-11 | Angel Companies Prediction System
        title: Angel Companies Prediction System
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed an AI-powered system to predict "Angels" for <mark>new accounts</mark> using machine learning and <mark>Google Search API</mark>. The system processes account data, <mark>extracts information</mark> from the internet, and utilizes a trained model to make predictions. Achieved a global accuracy of 62.38% on unseen data, with the ability to increase accuracy to 98.99% by implementing a <mark>confidence threshold</mark>. <a href="https://drive.google.com/file/d/1-h8zPJc1NzX68kj1H2Ez2GX1Cr0C3ohj" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, scikit-learn, Google Search API, NLTK, Pandas, NumPy, Pickle

          ---

      - layout: left #pid-36/2-13 | Inter-Annotator Agreement Analysis Tool for Hematology Analyzer 
        title: Inter-Annotator Agreement Analysis Tool for Hematology Analyzer 
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a Python-based tool to <mark>calculate</mark> and analyze inter-annotator agreement using Fleiss' Kappa and Krippendorff's Alpha <mark>metrics</mark>. The project involved implementing statistical algorithms, handling complex data structures, and interpreting results to assess <mark>reliability</mark> in annotation tasks. Explored limitations of agreement measures and their implications for <mark>data quality</mark> assessment in machine learning application of hematology. <a href="https://drive.google.com/file/d/1Ui-Go-VM4-hI9ovSDoPSQaqigYerE-sn" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, NumPy, statsmodels, Krippendorff

          ---

      - layout: left #pid-39/2-14 | Berkeley/Stanford Parser Evaluation and Analysis
        title: Berkeley/Stanford Parser Evaluation and Analysis
        link: https://github.com/rohanredtj/1_NLP_Parser/blob/master/berkely_stanford_parser_evalb.ipynb
        link_text: Project Code ðŸ”—
        
        description: |
          
          Implemented and evaluated the <mark>performance</mark> of the Berkeley and Stanford parsers on the Wall Street Journal <mark>corpus</mark>. Developed custom Python scripts to calculate parsing <mark>accuracy</mark> metrics like precision, recall, and F1 score. Conducted <mark>comparative analysis</mark> of parser outputs using the EVALB scoring program and visualized results. <a href="https://drive.google.com/file/d/1oRSf3-IbD_xBKeBPdRax2mrIqmGJk9RD" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, NLTK, Pandas, Matplotlib, Berkeley Parser, Stanford Parser, EVALB Evaluation


  - title: Data Analytics Projects
    layout: list
    content:

      - layout: left #pid-33/3-1 | Chartio Dashboards for Muitiple Business Functions
        title: Chartio Dashboards for Muitiple Business Functions
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed comprehensive Chartio dashboards <mark>integrating</mark> various business functions. Created interactive visualizations for <mark>conversion funnels</mark> and <mark>budget reports</mark>, enhancing data interpretation. Implemented <mark>alert systems</mark> for proactive monitoring and embedding capabilities for seamless integration. The project <mark>streamlined</mark> analytics processes, enabling data-driven decisions across departments and improving overall business intelligence. These dashboards provided a centralized platform for real-time data analysis and reporting. <a href="https://drive.google.com/file/d/17vpxQYwgKV9gUdxaoMjg768GNP8fAuQI" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Chartio, Data Visualization, Chart Embedding, Alerts

          ---

      - layout: left #pid-11/3-2 | Reverse ETL based Customer Data Integration Platform with Metabase
        title: Reverse ETL based Customer Data Integration Platform with Metabase
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Engineered a centralized reverse ETL customer data store, seamlessly <mark>integrating</mark> Hubspot, Klaviyo, and website tracking sources. Implemented robust <mark>data synchronization</mark> and conflict resolution mechanisms to ensure data integrity across platforms. Leveraged dbt for efficient data transformation and SQL for complex queries, creating a comprehensive, <mark>unified view</mark> of customer data, and visualization based on it in Metabase. This solution streamlined customer analytics and enabled more <mark>targeted marketing</mark> strategies. <a href="https://drive.google.com/file/d/1fCHU4JaJEkwM7tWxbhdFJL7jMWYKhC-j" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** DBT, Metabase, SQL, BigQuery, Airbyte, RudderStack, Klaviyo, Hubspot

          ---

      - layout: left #pid-60/3-3 | Data Platform Integration for Real-Time Analytics
        title: Data Platform Integration for Real-Time Analytics
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Engineered a <mark>cost-effective</mark>, real-time <mark>data pipeline</mark>, seamlessly integrating customer data platforms and analytics tools. The solution harnessed the power of Segment, RudderStack, and BigQuery to <mark>optimize</mark> data flow, significantly reduce latency, and enhance data accessibility. This robust infrastructure enabled real-time insights, facilitating data-driven decision-making and <mark>improving</mark> overall business intelligence capabilities. <a href="https://drive.google.com/file/d/1IdhvADpE2KEo1FECbztJrMWlYZbpuEsN" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Segment, RudderStack, BigQuery, Amplitude, Google Analytics 4

          ---

      - layout: left #pid-63/3-3.1 | Amplitude Analytics Implementation for Online Flower Business
        title: Amplitude Analytics Implementation for Online Flower Business
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Implemented advanced <mark>user analytics</mark> for an <mark>e-commerce</mark> platform using Amplitude. Developed custom dashboards for user <mark>journey analysis</mark> and product performance metrics. Created segment analysis to compare <mark>brand performance</mark>, focusing on flowers and drinks categories. Utilized data-driven insights to optimize user experience, <mark>increase conversions</mark>, and inform strategic decisions across various product lines. <a href="https://drive.google.com/file/d/1nLGjnAyQjRzIlfJZm70zM5GtsfmolYmk" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Amplitude Analytics, SQL, Data Visualization, E-commerce, Event Tracking, User Segmentation, Custom Metrics

          ---

      - layout: left #pid-16/3-4 | E-commerce Analytics Dashboard Development
        title: E-commerce Analytics Dashboard Development
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Designed and <mark>implemented</mark> comprehensive Cluvio-based <mark>dashboards</mark> for a major e-commerce company, providing real-time insights into <mark>key performance indicators</mark> (KPIs). The project focused on channel performance, revenue tracking, customer behavior analysis, and item performance metrics. These dashboards <mark>enabled</mark> data-driven <mark>decision-making</mark> by visualizing MTD, QTD, and YTD comparisons, revenue trends, customer lifetime value, and top-performing items. <a href="https://drive.google.com/file/d/1QzprVdSFUDZteSaUbHaT8i-KnVNPtryE" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Cluvio, SQL, Data Analysis, KPIs

          ---

      - layout: left #pid-43/3-5 | Qlksense Financial Dashboard - A/R Aging and Time Analysis
        title: Qlksense Financial Dashboard - A/R Aging and Time Analysis
        link: https://drive.google.com/file/d/1JpNLDZADihxt2tlifoakWs1h8MJlpstF
        link_text: Proprietary Work (Sample Dashboard ðŸ”—)
        
        description: |
          
          Developed a comprehensive financial Qliksense dashboard integrating <mark>accounts receivable</mark> aging and time analysis features. This tool provides real-time insights into AR transaction summaries, aging distributions, and designer performance metrics. The dashboard enables <mark>efficient tracking</mark> of outstanding payments, workload distribution, and project hours, facilitating improved financial management and <mark>resource allocation</mark> for the business. <a href="https://drive.google.com/file/d/1bkZheaCJ6pFiVP9f-PzS8rvFCtCS9QD1" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Qliksense, Data Visualization, DBMS, Financial Data, Interactive Design, Business Intelligence

          ---

      - layout: left #pid-13/3-6 | Superset Dashboard for Process Scoring System
        title: Superset Dashboard for Process Scoring System
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a scoring dashboard using Apache Superset to analyze and <mark>visualize performance</mark> metrics across multiple dimensions. Implemented time-based reporting, <mark>weighted scoring</mark>, and user comparison features. Integrated with MySQL database and explored materialized views for efficient data handling. Investigated API integrations and webhook implementations to enable <mark>real-time</mark> dashboard updates and notifications. <a href="https://drive.google.com/file/d/16LN9N7Y3FpOVzYEe3CpPhnHyJpIfk8v8" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Apache Superset, MySQL, Flask, Jinja, Docker, Git, RESTful APIs, Webhooks

          ---

      - layout: left #pid-4/3-7 | Sales Performance Tracking Dashboard using Looker
        title: Sales Performance Tracking Dashboard using Looker
        link: https://lookerstudio.google.com/reporting/2bb9d789-cfc0-408c-8e6c-ff4a2a1e7917
        link_text: Proprietary Work (Sample Dashboard ðŸ”—)
        
        description: |
          
          Developed a comprehensive sales tracking board to <mark>monitor</mark> and analyze <mark>sales associate</mark> performance. The dashboard features KPI tracking, scoreboard metrics, and visual representations of sales data. It allows for time-based <mark>filtering</mark> and provides a clear ranking system for sales associates. This tool enhances <mark>performance visibility</mark> and facilitates data-driven decision making in the sales department. <a href="https://drive.google.com/file/d/1gARfu23bbhtUQnqaYZ_AZJbY3sqmvqIF" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Looker Studio, SQL, Google Sheets

          ---

      - layout: left #pid-48/3-8 | Qliksense Data Visualization and Dashboard Development
        title: Qliksense Data Visualization and Dashboard Development
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed and optimized data visualization <mark>solutions</mark> using Qliksense and Qlikview. Created interactive dashboards for financial reporting, inventory planning, and social media analytics. Improved <mark>dashboard performance</mark> through backend script optimization. Provided custom solutions for <mark>diverse industries</mark> including healthcare, finance, and marketing. <a href="https://drive.google.com/file/d/1UqBcuKnd3BvE3Gs61QoBXGQORzD2PyYw" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Qliksense, Qlikview, Qlik Web Connectors, Idevio Maps, SQL

          ---

      - layout: left #pid-34/3-8.1 | Financial Data Analysis and MacBeth Risk Assessment
        title: Financial Data Analysis and MacBeth Risk Assessment
        link: https://docs.google.com/spreadsheets/d/1J_Xz8l7_C2oMBUBwA797p8vSe0Mfe1RceiguKWLelTo
        link_text: Proprietary Work (Sample Sheet ðŸ”—)
        
        description: |
          
          Conducted comprehensive financial data analysis on a <mark>multi-year dataset</mark> (2013-2017) to assess <mark>investment performance</mark> and risk factors. Utilized advanced statistical methods including regression analysis, beta calculations, and MacBeth risk <mark>premium estimation</mark>. Evaluated fund flows, returns, and risk metrics across multiple product references to provide insights for informed investment decisions. <a href="https://drive.google.com/file/d/1ZFaLagBO30uy-LR_nGQPyM-2Hn7mQnxS" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Excel, Statistical Analysis, Time Series, Financial Modeling


  - title: Software Engineering Projects
    layout: list
    content:

      - layout: left #pid-53/4-0.9 | Real-time Job Notification System
        title: Real-time Job Notification System
        link: https://www.trendsonup.com
        link_text: Website ðŸ”—
        
        description: |
          
          TrendsOnUp is a freelancer-focused <mark>web application</mark> that provides real-time email <mark>notifications</mark> for Upwork <mark>job postings</mark>. It allows users to receive alerts for opportunities <mark>matching</mark> their skills and preferences, helping them stay ahead in their freelance careers. This free service empowers freelancers worldwide by enabling them to quickly respond to relevant job openings in the <mark>Upwork</mark> marketplace. <a href="https://drive.google.com/file/d/1xa8iIIcAaGLANBKdff1KJnkDb98KKOYP" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** HTML, JavaScript, CSS, Email integration, Cloud Infrastructure

          ---

      - layout: left #pid-53/4-1 | Job Application Bestie - AI Powered Cover Letter Creator
        title: Job Application Bestie - AI Powered Cover Letter Creator
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Job Application Bestie is a <mark>web-based</mark> platform designed to streamline the job application process. It offers tools for crafting <mark>personalized cover letters</mark>, managing job applications, and leveraging AI assistance. The platform provides a <mark>user-friendly</mark> interface for job seekers to create professional applications, track their progress, and increase their chances of securing interviews. <a href="https://drive.google.com/file/d/1_9LAvpyiwSyPkE6OuZw2F-f244KuHAD4" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Django, HTML/CSS, JavaScript, OpenAI API, PDF Generation, MySQL

          ---

      - layout: left #pid-25/4-2 | Link Grammar Dictionary Visualization in Python
        title: Link Grammar Dictionary Visualization in Python
        link: https://github.com/rohanredtj/Link-Grammer-Dictionary-Visualization-Python
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed a Python-based tool to visualize Link Grammar dictionaries, focusing on <mark>5-word clusters</mark>. Transformed grammar data into <mark>ontology</mark> format using rdflib, then generated interactive graph visualizations with ontospy. This <mark>innovative approach</mark> enables exploration of linguistic structures through ontology-based representations, offering new insights into <mark>language patterns</mark> and relationships. <a href="https://drive.google.com/file/d/10KTnp1e9k92i1aONLCBgp4v9Eg43whQt" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, rdflib, Ontospy, RDF/OWL, Visualization

          ---

      - layout: left #pid-20/4-3 | Publisher Analysis and Classification Tool
        title: Publisher Analysis and Classification Tool
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Django-based tool for analyzing and <mark>classifying publishers</mark> from Google Sheets data. The system <mark>automates</mark> the process of identifying known publishers, <mark>marking them</mark> in spreadsheets, and calculating <mark>publication statistics</mark>. It features data processing, API integration, and text analysis capabilities, streamlining the workflow for <mark>publisher recognition</mark> and analysis. <a href="https://drive.google.com/file/d/1NMOSL1jR-EDocNm-4jjlpBc22qxMMqbx" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Django, Google Sheets API, Pandas, TextHero


  - title: Other Projects
    layout: list
    content:

      - layout: left #pid-51/5-1 | Hindi LLM Red Team Project
        title: Hindi LLM Red Team Project
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Led several red team projects to evaluate and <mark>stress-test</mark> Large Language Models (LLMs) for Hindi language processing. Managed a team of annotators tasked with breaking the <mark>model's performance</mark>, specifically targeting products like Google Gemini. This project aimed to <mark>identify vulnerabilities</mark>, biases, and limitations in Hindi language understanding and generation within cutting-edge AI systems. <a href="https://drive.google.com/file/d/1fct7ekkWUqxx7BMO7-RcrNczHUQXQSDq" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Large Language Models (LLMs), Hindi Language Datasets, AI Testing Frameworks, Data Annotation Platforms


footer_show_references: false


remote_theme: rohanredtj/modern-resume-theme


sass:
  sass_dir: _sass
  style: compressed


plugins:
 - jekyll-seo-tag
