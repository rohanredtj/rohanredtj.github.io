repository: sproogen/resume-theme


favicon: images/favicon.ico


version: 2


name: Rohan Rathore
title: Data Engineer | Bengaluru, India
phone_title: Contact 
phone: rohan.rathore93@gmail.com
email_title: Status
email: Verified Expert


darkmode: never


twitter_username: rohanredtj
github_username:  rohanredtj
linkedin_username: rohanredtj
instagram_username: rohanredtj


additional_links:
- title: Hire Rohan
  icon: fas fa-briefcase
  url: https://www.upwork.com/freelancers/~01ee871ca78c1a805c


about_profile_image: images/profile.jpg
about_content: |

  ## **Expertise**
  <blockquote><span class="block-main"><svg width="12" height="12" viewBox="0 0 14 14" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="m7 10.5-4.114 2.163.785-4.581L.343 4.837l4.6-.669L7 0l2.057 4.168 4.6.669-3.328 3.245.785 4.581z"></path></svg>Data Engineering</span> <span class="block-secondary">Data Analysis</span> <span class="block-secondary">Data Warehousing</span> <span class="block-secondary">ETL</span> <span class="block-secondary">Big Data</span> <span class="block-secondary">Cloud Platforms</span> <span class="block-secondary">Data Modeling</span> <span class="block-secondary">Database Design</span> <span class="block-secondary">Data Pipeline Architecture</span> <span class="block-secondary">Version Control</span> <span class="block-secondary">Containerization</span></blockquote>
  
  ## **Portfolio Projects**
  [Data Engineering](#data-engineering-projects), [Data Science](#data-science-projects)
  <br><br> 
  
  ## **Bio**
  Rohan is a data professional with 7 years of experience, two master's degrees, and a proven track record of working with US-based companies. His expertise spans the entire data lifecycle, from data engineering and analytics to visualization and machine learning, allowing him to quickly adapt to new technologies and methodologies. Rohan's international exposure, diverse skill set, and eagerness to learn make him well-equipped to tackle complex data challenges and drive impactful solutions in fast-paced environments.
  <br><br> 

  ## **Experience**
  <blockquote><span class="block-secondary">Python - 6 years</span> <span class="block-secondary">Predictive Modeling - 6 years</span> <span class="block-secondary">SQL - 5 years</span> <span class="block-secondary">BigQuery - 3 years</span> <span class="block-secondary">Data Modelling - 3 years</span> <span class="block-secondary">Keras - 3 years</span> <span class="block-secondary">Django - 2 years</span> <span class="block-secondary">Amazon Web Services (AWS) - 2 years</span> <span class="block-secondary">PySpark - 2 years</span> <span class="block-secondary">DBT - 2 years</span> <span class="block-secondary">Docker - 1 years</span></blockquote>

  ## **Education**
  - Master of Science in Business Consulting, Furtwangen University, Germany ([Master Thesis](https://drive.google.com/file/d/1b4AR98QbptOp3krVO1BYh-TDCWeSl1U1/view?usp=drive_link))
  - Master of Science in Big Data Analytics & AI, Novosibirsk State University, Russia ([Master Thesis](https://link.springer.com/chapter/10.1007/978-981-16-5747-4_73))
  - Bachelor of Technology in Engineering Physics, Delhi Technological University, India
  <br><br> 

  ## **Certifications**
  - Dell EMC Data Science Assiociate ([NCB172QTLEFQQG55](https://www.certmetrics.com/dell/public/verification.aspx))
  <br><br> 

  ## **Skills**
  - **Libraries/APIs** - Pandas, NumPy, Scikit-learn, Apache Spark, Django
  - **Tools** - DBT, Docker, Apache Airflow
  - **Languages** - Python, SQL, R
  - **Paradigms** - ETL/ELT, Data Modeling, Data Warehousing, Big Data Processing
  - **Platforms** - MySQL, PostgreSQL, Amazon Web Services (AWS), Google Cloud Platform (GCP)
  - **Storage** - Amazon Redshift, Google BigQuery, Snowflake
  - **Other** - Data Pipeline Design, Data Quality Management, Data Analytics, Machine Learning
  <br><br>  

  ## **Preferred Environment**
  Visual Studio Code (VS Code), Amazon Web Services (AWS), Google Colab, MacOS


content:

  - title: Data Engineering Projects
    layout: list
    content:
      - layout: left #pid-52/1-1 | AWS-Powered Zillow Data Pipeline for Real Estate Analytics
        title: AWS-Powered Zillow Data Pipeline for Real Estate Analytics
        link: https://github.com/rohanredtj/aws-zillow-pipeline
        link_text: Proprietary Work (Sample Code ðŸ”—)  
        
        description: |     
          
          Engineered a data pipeline using medallion architecture for <mark>Zillow data</mark>, processing 1GB of daily scraped CSV files from AWS S3. Implemented <mark>data cleaning</mark> and standardization for 180 columns, storing results in Parquet format with Hive partitioning. Deployed as an AWS Lambda function with <mark>scheduled execution</mark> via CloudWatch, optimized for 3GB RAM allocation. <a href="https://drive.google.com/file/d/1rL68kHLu2Z5LXJMa2lstjNVX4ScQE-Vm" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** AWS S3, AWS Lambda, AWS CloudWatch, AWS CLI, Python, Pandas, PyArrow, CSV, Parquet, Hive partitioning

          ---

      - layout: left #pid-59/1-2 | Wiktionary Abbreviation Extractor for Legal Documents
        title: Wiktionary Abbreviation Extractor for Legal Documents
        link: https://github.com/rohanredtj/wiktionary-abbreviation-extractor
        link_text: Proprietary Work (Sample Code ðŸ”—)
        
        description: |
          
          Developed a sophisticated tool to extract and analyze abbreviations from <mark>Wiktionary dumps</mark>. The project involved <mark>parsing</mark> complex data structures, implementing custom algorithms for <mark>abbreviation detection</mark>, and handling various <mark>edge cases</mark> to ensure comprehensive coverage of linguistic variations. <a href="https://drive.google.com/file/d/11qORN-eejKRDXU4gUtZ9K6gReftltyUx" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XML processing libraries, regular expressions, data structures, version control (Git), shell scripting

          ---

      - layout: left #pid-15/1-3 | PySpark-Based Oil Price Prediction Model
        title: PySpark-Based Oil Price Prediction Model
        link: /#
        link_text: Proprietary Work
        
        description: |     
          
          Developed a sophisticated <mark>machine learning model</mark> using PySpark to <mark>predict oil prices</mark> based on comprehensive oil field data. This project leveraged big data technologies to process and <mark>analyze</mark> large-scale datasets, enhancing decision-making capabilities in the energy sector. The model incorporated various predictive techniques, including Facebook Prophet, and was <mark>deployed</mark> on AWS infrastructure for scalable performance and real-time insights. <a href="https://drive.google.com/file/d/10Iw-aw1UkWZfd7xZuEdnhKuP0u_ppZkr" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** PySpark, AWS EC2 (r5.2xlarge instances), Jupyter Notebook, Facebook Prophet, Scikit-learn, Apache Superset, AWS S3, SSH, Python

          ---

      - layout: left #pid-10/1-4 | Database Migration from Snowflake to PostgreSQL
        title: Database Migration from Snowflake to PostgreSQL
        link: https://github.com/rohanredtj/snowflake-to-postgres
        link_text: Project Code ðŸ”— 

        description: |     
          
          Developed a robust Python script to <mark>automate</mark> the process of <mark>migrating data</mark> from Snowflake to PostgreSQL. This tool ensures <mark>efficient</mark> and error-free data transfer between disparate database systems. It handles schema creation, table synchronization, and large-scale data movement with <mark>built-in error handling</mark>. The script also generates timestamped schemas for version control and easy rollback if needed. <a href="https://drive.google.com/file/d/11jFpgXil8EomlGrV_S6AAaZOt38fjC0b" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, SQLAlchemy, Pandas, Snowflake, PostgreSQL, SQL

          ---

      - layout: left #pid-8/1-5 | Automated Name Parsing for Healthcare Provider Lists
        title: Automated Name Parsing for Healthcare Provider Lists
        link: https://colab.research.google.com/drive/1aG3_g9X8F21TmTy_DnFSk-ljSRgPDQas?usp=drive_link
        link_text: Project Code ðŸ”— 
        
        description: |     
          
          Engineered a sophisticated Python-based system utilizing OpenAI to automate the <mark>extraction and parsing</mark> of healthcare provider information from diverse state-specific files. The system adeptly handles multiple file formats including PDF, Excel, and CSV, processing data from over <mark>10 different states</mark>. It manages complex variations in data structure, ensuring clean and accurate output for <mark>internal compliance</mark> and monitoring use. <a href="https://drive.google.com/file/d/10jpIEh0clB5KAGy05o_ADhV5tH-ZwWlV" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, OpenAI API, CSV handling libraries, Time management and logging tools

          ---

      - layout: left #pid-22/1-6 | Web Scraping Forbes Russia Top 200 Private Companies
        title: Web Scraping Forbes Russia Top 200 Private Companies
        link: https://colab.research.google.com/drive/1TJsT8sICYtkmeikV2H1kojG_aubV--4S?usp=sharing
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed a Python script to <mark>extract</mark> and structure data from <mark>Forbes Russia's</mark> list of top 200 private companies. The project involved web scraping techniques to gather <mark>detailed information</mark> including company rankings, names, financial data, industry sectors, management details, and geographical information. The extracted data was then organized into a comprehensive <mark>dataset</mark>, enabling in-depth analysis of Russia's leading private businesses. <a href="https://drive.google.com/file/d/1HYqJTY0_iO6vJimLq-FhVoSCaKSPOObe" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, BeautifulSoup, Pandas, NumPy, Requests, tqdm

      - layout: left #pid-31/1-7 | Anime Season Scraper Web Scraping Tool for MyAnimeList
        title: Anime Season Scraper Web Scraping Tool for MyAnimeList
        link: https://colab.research.google.com/drive/1gOYiXsQ7g-83GPFfpBjDfiqex_X1jHuF?usp=sharing
        link_text: Project Code ðŸ”—
        
        description: |     
          
          This project developed a web <mark>scraping</mark> tool to collect seasonal <mark>anime data</mark> from MyAnimeList. The script uses the MyAnimeList API to fetch information about anime releases for specified years and seasons. It then processes and organizes this data into a <mark>structured format</mark> using Pandas, saving the results as a CSV file for further analysis or use in other applications. <a href="https://drive.google.com/file/d/15qBzkr_Z3m0hdmlWneWu5yPtdq2niXy1" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Pandas, Requests, MyAnimeList API


  - title: Data Science Projects
    layout: list
    content:
      - layout: left #pid-1/2-2 | YouTube Insights Analysis for Channel Performance
        title: YouTube Insights Analysis for Channel Performance
        link: https://colab.research.google.com/drive/1QWBifUwjdk7RVRA_-wHO2j9lEcIQlLq9
        link_text: Project Code ðŸ”—
        
        description: |     
          
          Conducted comprehensive <mark>data analysis</mark> on global YouTube statistics to uncover <mark>success factors</mark> for top channels. Employed <mark>machine learning</mark> techniques, including Random Forest Classifier, to identify key performance indicators. <mark>Visualized</mark> insights through <mark>geospatial</mark> analysis using GeoPandas. Explored correlations between channel metrics, subscriber growth, and earnings. Analyzed <mark>popular content</mark> categories and regional influencers' global impact. Developed <mark>actionable insights</mark> for content creators to optimize channel performance. <a href="https://drive.google.com/file/d/1eptYghvHy2rS7Oeq12cV8TaUHCjHdW6d" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>

          **Technologies:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, GeoPandas, Google Colab

          ---

      - layout: left #pid-9/2-3 | PDF Q&A Bestie - LLM RAG
        title: PDF Q&A Bestie - LLM RAG
        link: https://github.com/rohanredtj/QnA-Bestie-On-PDF
        link_text: Project Code ðŸ”—
        
        description: |
          
          PDF Q&A Bestie is an innovative app that enables users to <mark>upload PDF</mark> files and <mark>ask questions</mark> about their content. Powered by the <mark>Llama2</mark> AI model, it provides <mark>accurate answers</mark> extracted directly from the uploaded documents. This project leverages Replicate API to offer a computationally efficient solution with a free quota, making advanced AI capabilities accessible to users. <a href="https://drive.google.com/file/d/1D9mFPPEaznibyRoe3mmxQ7M5r9gDq1_G" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Llama2, Replicate API, Langchain, Pinecone, Streamlit, Python, Hugging Face Embeddings, PyPDF Loader

          ---

      - layout: left #pid-61/2-4 | Data Science Consulting for Real Estate
        title: Data Science Consulting for Real Estate
        link: https://www.kaggle.com/code/rohankaggler/property-price-prediction
        link_text: Project Code ðŸ”—
        
        description: |
          
          Conducted data analysis and <mark>business consulting</mark> for client's portfolio companies. Analyzed UK housing prices to provide actionable insights and propose advanced <mark>analytics strategies</mark>. Performed descriptive, exploratory, and <mark>predictive analyses</mark> to enhance business operations and decision-making. Delivered comprehensive presentations to company executives, focusing on <mark>data-driven</mark> solutions and value extraction from available datasets. <a href="https://drive.google.com/file/d/1RSfnalGbckeHN7w2WVCKe4TXrJ_8iOpU" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** R, Data Visualization, Statistical Analysis, Geospatial Analysis, Large Dataset, Kaggle Notebook


footer_show_references: false


remote_theme: sproogen/resume-theme


sass:
  sass_dir: _sass
  style: compressed


plugins:
 - jekyll-seo-tag
