repository: sproogen/resume-theme


favicon: images/favicon.ico


version: 2


name: Rohan Rathore
title: Data Engineer | Bengaluru, India
phone_title: Contact 
phone: rohan.rathore93@gmail.com
email_title: Status
email: Verified Expert


darkmode: never


twitter_username: rohanredtj
github_username:  rohanredtj
linkedin_username: rohanredtj
instagram_username: rohanredtj


additional_links:
- title: Hire Rohan
  icon: fas fa-briefcase
  url: https://www.upwork.com/freelancers/~01ee871ca78c1a805c


about_profile_image: images/profile.jpg
about_content: |

  ## **Expertise**
  <blockquote><span class="block-main"><svg width="12" height="12" viewBox="0 0 14 14" fill="currentColor" xmlns="http://www.w3.org/2000/svg"><path d="m7 10.5-4.114 2.163.785-4.581L.343 4.837l4.6-.669L7 0l2.057 4.168 4.6.669-3.328 3.245.785 4.581z"></path></svg>Data Engineering</span> <span class="block-secondary">Data Analysis</span> <span class="block-secondary">Data Warehousing</span> <span class="block-secondary">ETL</span> <span class="block-secondary">Big Data</span> <span class="block-secondary">Cloud Platforms</span> <span class="block-secondary">Data Modeling</span> <span class="block-secondary">Database Design</span> <span class="block-secondary">Data Pipeline Architecture</span> <span class="block-secondary">Version Control</span> <span class="block-secondary">Containerization</span></blockquote>
  
  ## **Portfolio Projects**
  [Data Engineering](#data-engineering-projects), [Data Science](#data-science-projects), [Data Analytics](#data-analytics-projects)
  <br><br> 
  
  ## **Bio**
  Rohan is a data professional with 7 years of experience, two master's degrees, and a proven track record of working with US-based companies. His expertise spans the entire data lifecycle, from data engineering and analytics to visualization and machine learning, allowing him to quickly adapt to new technologies and methodologies. Rohan's international exposure, diverse skill set, and eagerness to learn make him well-equipped to tackle complex data challenges and drive impactful solutions in fast-paced environments.
  <br><br> 

  ## **Experience**
  <blockquote><span class="block-secondary">Python - 6 years</span> <span class="block-secondary">Predictive Modeling - 6 years</span> <span class="block-secondary">SQL - 5 years</span> <span class="block-secondary">BigQuery - 3 years</span> <span class="block-secondary">Data Modelling - 3 years</span> <span class="block-secondary">Keras - 3 years</span> <span class="block-secondary">Django - 2 years</span> <span class="block-secondary">Amazon Web Services (AWS) - 2 years</span> <span class="block-secondary">PySpark - 2 years</span> <span class="block-secondary">DBT - 2 years</span> <span class="block-secondary">Docker - 1 years</span></blockquote>

  ## **Education**
  - Master of Science in Business Consulting, Furtwangen University, Germany ([Master Thesis](https://drive.google.com/file/d/1b4AR98QbptOp3krVO1BYh-TDCWeSl1U1/view?usp=drive_link))
  - Master of Science in Big Data Analytics & AI, Novosibirsk State University, Russia ([Master Thesis](https://link.springer.com/chapter/10.1007/978-981-16-5747-4_73))
  - Bachelor of Technology in Engineering Physics, Delhi Technological University, India
  <br><br> 

  ## **Certifications**
  - Dell EMC Data Science Assiociate ([NCB172QTLEFQQG55](https://www.certmetrics.com/dell/public/verification.aspx))
  <br><br> 

  ## **Skills**
  - **Libraries/APIs** - Pandas, NumPy, Scikit-learn, Apache Spark, Django
  - **Tools** - DBT, Docker, Apache Airflow
  - **Languages** - Python, SQL, R
  - **Paradigms** - ETL/ELT, Data Modeling, Data Warehousing, Big Data Processing
  - **Platforms** - MySQL, PostgreSQL, Amazon Web Services (AWS), Google Cloud Platform (GCP)
  - **Storage** - Amazon Redshift, Google BigQuery, Snowflake
  - **Other** - Data Pipeline Design, Data Quality Management, Data Analytics, Machine Learning
  <br><br>  

  ## **Preferred Environment**
  Visual Studio Code (VS Code), Amazon Web Services (AWS), Google Colab, MacOS


content:

  - title: Data Engineering Projects
    layout: list
    content:

      - layout: left #pid-52/1-1 | AWS-Powered Zillow Data Pipeline for Real Estate Analytics
        title: AWS-Powered Zillow Data Pipeline for Real Estate Analytics
        link: https://github.com/rohanredtj/aws-zillow-pipeline
        link_text: Proprietary Work (Sample Code ðŸ”—)  
        
        description: |     
          
          Engineered a data pipeline using medallion architecture for <mark>Zillow data</mark>, processing 1GB of daily scraped CSV files from AWS S3. Implemented <mark>data cleaning</mark> and standardization for 180 columns, storing results in Parquet format with Hive partitioning. Deployed as an AWS Lambda function with <mark>scheduled execution</mark> via CloudWatch, optimized for 3GB RAM allocation. <a href="https://drive.google.com/file/d/1rL68kHLu2Z5LXJMa2lstjNVX4ScQE-Vm" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** AWS S3, AWS Lambda, AWS CloudWatch, AWS CLI, Python, Pandas, PyArrow, CSV, Parquet, Hive partitioning

          ---

      - layout: left #pid-59/1-2 | Wiktionary Abbreviation Extractor for Legal Documents
        title: Wiktionary Abbreviation Extractor for Legal Documents
        link: https://github.com/rohanredtj/wiktionary-abbreviation-extractor
        link_text: Proprietary Work (Sample Code ðŸ”—)
        
        description: |
          
          Developed a sophisticated tool to extract and analyze abbreviations from <mark>Wiktionary dumps</mark>. The project involved <mark>parsing</mark> complex data structures, implementing custom algorithms for <mark>abbreviation detection</mark>, and handling various <mark>edge cases</mark> to ensure comprehensive coverage of linguistic variations. <a href="https://drive.google.com/file/d/11qORN-eejKRDXU4gUtZ9K6gReftltyUx" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XML processing libraries, regular expressions, data structures, version control (Git), shell scripting

          ---

      - layout: left #pid-15/1-3 | PySpark-Based Oil Price Prediction Model
        title: PySpark-Based Oil Price Prediction Model
        link: /#
        link_text: Proprietary Work
        
        description: |     
          
          Developed a sophisticated <mark>machine learning model</mark> using PySpark to <mark>predict oil prices</mark> based on comprehensive oil field data. This project leveraged big data technologies to process and <mark>analyze</mark> large-scale datasets, enhancing decision-making capabilities in the energy sector. The model incorporated various predictive techniques, including Facebook Prophet, and was <mark>deployed</mark> on AWS infrastructure for scalable performance and real-time insights. <a href="https://drive.google.com/file/d/10Iw-aw1UkWZfd7xZuEdnhKuP0u_ppZkr" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** PySpark, AWS EC2 (r5.2xlarge instances), Jupyter Notebook, Facebook Prophet, Scikit-learn, Apache Superset, AWS S3, SSH, Python

          ---

      - layout: left #pid-10/1-4 | Database Migration from Snowflake to PostgreSQL
        title: Database Migration from Snowflake to PostgreSQL
        link: https://github.com/rohanredtj/snowflake-to-postgres
        link_text: Project Code ðŸ”— 

        description: |     
          
          Developed a robust Python script to <mark>automate</mark> the process of <mark>migrating data</mark> from Snowflake to PostgreSQL. This tool ensures <mark>efficient</mark> and error-free data transfer between disparate database systems. It handles schema creation, table synchronization, and large-scale data movement with <mark>built-in error handling</mark>. The script also generates timestamped schemas for version control and easy rollback if needed. <a href="https://drive.google.com/file/d/11jFpgXil8EomlGrV_S6AAaZOt38fjC0b" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, SQLAlchemy, Pandas, Snowflake, PostgreSQL, SQL

          ---

      - layout: left #pid-8/1-5 | Automated Name Parsing for Healthcare Provider Lists
        title: Automated Name Parsing for Healthcare Provider Lists
        link: https://colab.research.google.com/drive/1aG3_g9X8F21TmTy_DnFSk-ljSRgPDQas?usp=drive_link
        link_text: Project Code ðŸ”— 
        
        description: |     
          
          Engineered a sophisticated Python-based system utilizing OpenAI to automate the <mark>extraction and parsing</mark> of healthcare provider information from diverse state-specific files. The system adeptly handles multiple file formats including PDF, Excel, and CSV, processing data from over <mark>10 different states</mark>. It manages complex variations in data structure, ensuring clean and accurate output for <mark>internal compliance</mark> and monitoring use. <a href="https://drive.google.com/file/d/10jpIEh0clB5KAGy05o_ADhV5tH-ZwWlV" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, OpenAI API, CSV handling libraries, Time management and logging tools

          ---

      - layout: left #pid-22/1-6 | Web Scraping Forbes Russia Top 200 Private Companies
        title: Web Scraping Forbes Russia Top 200 Private Companies
        link: https://colab.research.google.com/drive/1TJsT8sICYtkmeikV2H1kojG_aubV--4S?usp=sharing
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed a Python script to <mark>extract</mark> and structure data from <mark>Forbes Russia's</mark> list of top 200 private companies. The project involved web scraping techniques to gather <mark>detailed information</mark> including company rankings, names, financial data, industry sectors, management details, and geographical information. The extracted data was then organized into a comprehensive <mark>dataset</mark>, enabling in-depth analysis of Russia's leading private businesses. <a href="https://drive.google.com/file/d/1HYqJTY0_iO6vJimLq-FhVoSCaKSPOObe" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, BeautifulSoup, Pandas, NumPy, Requests, tqdm

      - layout: left #pid-31/1-7 | Anime Season Scraper Web Scraping Tool for MyAnimeList
        title: Anime Season Scraper Web Scraping Tool for MyAnimeList
        link: https://colab.research.google.com/drive/1gOYiXsQ7g-83GPFfpBjDfiqex_X1jHuF?usp=sharing
        link_text: Project Code ðŸ”—
        
        description: |     
          
          This project developed a web <mark>scraping</mark> tool to collect seasonal <mark>anime data</mark> from MyAnimeList. The script uses the MyAnimeList API to fetch information about anime releases for specified years and seasons. It then processes and organizes this data into a <mark>structured format</mark> using Pandas, saving the results as a CSV file for further analysis or use in other applications. <a href="https://drive.google.com/file/d/15qBzkr_Z3m0hdmlWneWu5yPtdq2niXy1" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Pandas, Requests, MyAnimeList API


  - title: Data Science Projects
    layout: list
    content:

      - layout: left #pid-12/2-1 | System Cancel Rate Prediction Model
        title: System Cancel Rate Prediction Model
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a machine learning model to accurately <mark>predict</mark> the system cancel rate for new jobs using pre-defined features. This model significantly <mark>improves</mark> customer lifetime value <mark>(LTV)</mark> predictions, enabling more efficient <mark>paid marketing</mark> campaigns and optimizing cleaner acquisition strategies. The project directly impacts business growth and operational efficiency. <a href="https://drive.google.com/file/d/1xg6tEgERrGU0m7Q50_xosdY3AL0U-c0G" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, Machine Learning, Keras, Optuna, Data Analysis, Feature Engineering, Data Visualization

          ---

      - layout: left #pid-1/2-2 | YouTube Insights Analysis for Channel Performance
        title: YouTube Insights Analysis for Channel Performance
        link: https://colab.research.google.com/drive/1QWBifUwjdk7RVRA_-wHO2j9lEcIQlLq9
        link_text: Project Code ðŸ”—
        
        description: |     
          
          Conducted comprehensive <mark>data analysis</mark> on global YouTube statistics to uncover <mark>success factors</mark> for top channels. Employed <mark>machine learning</mark> techniques, including Random Forest Classifier, to identify key performance indicators. <mark>Visualized</mark> insights through <mark>geospatial</mark> analysis using GeoPandas. Explored correlations between channel metrics, subscriber growth, and earnings. Analyzed <mark>popular content</mark> categories and regional influencers' global impact. Developed <mark>actionable insights</mark> for content creators to optimize channel performance. <a href="https://drive.google.com/file/d/1eptYghvHy2rS7Oeq12cV8TaUHCjHdW6d" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>

          **Technologies:** Python, Pandas, NumPy, Scikit-learn, Matplotlib, Seaborn, GeoPandas, Google Colab

          ---

      - layout: left #pid-9/2-3 | PDF Q&A Bestie - LLM RAG
        title: PDF Q&A Bestie - LLM RAG
        link: https://github.com/rohanredtj/QnA-Bestie-On-PDF
        link_text: Project Code ðŸ”—
        
        description: |
          
          PDF Q&A Bestie is an innovative app that enables users to <mark>upload PDF</mark> files and <mark>ask questions</mark> about their content. Powered by the <mark>Llama2</mark> AI model, it provides <mark>accurate answers</mark> extracted directly from the uploaded documents. This project leverages Replicate API to offer a computationally efficient solution with a free quota, making advanced AI capabilities accessible to users. <a href="https://drive.google.com/file/d/1D9mFPPEaznibyRoe3mmxQ7M5r9gDq1_G" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Llama2, Replicate API, Langchain, Pinecone, Streamlit, Python, Hugging Face Embeddings, PyPDF Loader

          ---

      - layout: left #pid-61/2-4 | Data Science Consulting for Real Estate
        title: Data Science Consulting for Real Estate
        link: https://www.kaggle.com/code/rohankaggler/property-price-prediction
        link_text: Project Code ðŸ”—
        
        description: |
          
          Conducted data analysis and <mark>business consulting</mark> for client's portfolio companies. Analyzed UK housing prices to provide actionable insights and propose advanced <mark>analytics strategies</mark>. Performed descriptive, exploratory, and <mark>predictive analyses</mark> to enhance business operations and decision-making. Delivered comprehensive presentations to company executives, focusing on <mark>data-driven</mark> solutions and value extraction from available datasets. <a href="https://drive.google.com/file/d/1iktbuAjz3H3LJmkt1FlJa0TXBgpk1m4p" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** R, Data Visualization, Statistical Analysis, Geospatial Analysis, Large Dataset, Kaggle Notebook

          ---

      - layout: left #pid-40/2-7 | Churn Prediction Model using XGBoost for Zenefits
        title: Churn Prediction Model using XGBoost for Zenefits
        link: https://colab.research.google.com/drive/1iJuzr62APaozFEF_WV_12WofcRqQ1r1r
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed a machine learning model to <mark>predict</mark> customer <mark>churn</mark> using XGBoost, an advanced gradient boosting algorithm. Achieved <mark>high accuracy</mark> and AUC scores through feature engineering and hyperparameter tuning. Implemented cross-validation for model optimization. This project enhanced the company's ability to proactively <mark>retain customers</mark> and improve business outcomes. <a href="https://drive.google.com/file/d/1d1wc_LWn1MUnRFg61mEaVyoJkrSmm8ba" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XGBoost, Pandas, NumPy, Scikit-learn, Matplotlib

          ---

      - layout: left #pid-18/2-8 | Product Recommendation System with LightGBM and Optuna
        title: Product Recommendation System with LightGBM and Optuna
        link: https://github.com/rohanredtj/product-recommendation-lightgbm
        link_text: Project Code ðŸ”—
        
        description: |
          
          Developed an advanced product recommendation system using machine learning techniques. The project involved data preprocessing, <mark>feature engineering</mark>, and model optimization to predict customer purchases. Implemented cross-validation for <mark>robust evaluation</mark> and utilized Optuna for hyperparameter tuning. The system aims to enhance <mark>sales predictions</mark> and improve <mark>customer targeting</mark> for a more efficient sales strategy. <a href="https://drive.google.com/file/d/1sLJ8FKL913tpiqgpQrc3Da4qPEQR_s85" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, pandas, scikit-learn, LightGBM, Optuna, NumPy, Tmux

          ---

      - layout: left #pid-14/2-9 | Predictive Model for Recruitment Time Estimation
        title: Predictive Model for Recruitment Time Estimation
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed an advanced machine learning model to <mark>predict</mark> recruitment <mark>fill times</mark> for job postings. The project involved data preprocessing, feature engineering, and implementing multiple XGBoost models for different <mark>pay structures</mark>. The final model significantly <mark>outperformed</mark> the baseline, enabling data-driven hiring strategies and significantly enhancing workforce planning efficiency. <a href="https://drive.google.com/file/d/1XHsm98nSaCGYXdwePMqVfTDJpJkEHwxP" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, XGBoost, Keras-TensorFlow, Feature Engineering, RMSE, Time Series Analysis

      - layout: left #pid-26/2-10 | Dialogflow Based Intelligent Virtual Assistant Chatbot
        title: Dialogflow Based Intelligent Virtual Assistant Chatbot
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a <mark>chatbot</mark> to provide instant responses to prospective applicants' queries about an educational program. The chatbot automates <mark>FAQ handling</mark>, enhances user satisfaction, and streamlines communication across multiple platforms, including the institution's website and social media channels. It features intent recognition, multi-language support, and <mark>seamless integration</mark> with existing systems. The solution significantly reduces response times and improves <mark>information accessibility</mark> for potential students. <a href="https://drive.google.com/file/d/1r3fIrhY_QVmVZgnqBHcEWbVx7SoCg2az" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Dialogflow, Python, HTTPS Protocol, Social Media APIs

      - layout: left #pid-17/2-11 | Angel Companies Prediction System
        title: Angel Companies Prediction System
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed an AI-powered system to predict "Angels" for <mark>new accounts</mark> using machine learning and <mark>Google Search API</mark>. The system processes account data, <mark>extracts information</mark> from the internet, and utilizes a trained model to make predictions. Achieved a global accuracy of 62.38% on unseen data, with the ability to increase accuracy to 98.99% by implementing a <mark>confidence threshold</mark>. <a href="https://drive.google.com/file/d/1-h8zPJc1NzX68kj1H2Ez2GX1Cr0C3ohj" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, scikit-learn, Google Search API, NLTK, Pandas, NumPy, Pickle

          ---

      - layout: left #pid-36/2-13 | Inter-Annotator Agreement Analysis Tool for Hematology Analyzer 
        title: Inter-Annotator Agreement Analysis Tool for Hematology Analyzer 
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Developed a Python-based tool to <mark>calculate</mark> and analyze inter-annotator agreement using Fleiss' Kappa and Krippendorff's Alpha <mark>metrics</mark>. The project involved implementing statistical algorithms, handling complex data structures, and interpreting results to assess <mark>reliability</mark> in annotation tasks. Explored limitations of agreement measures and their implications for <mark>data quality</mark> assessment in machine learning application of hematology. <a href="https://drive.google.com/file/d/1Ui-Go-VM4-hI9ovSDoPSQaqigYerE-sn" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, NumPy, statsmodels, Krippendorff

          ---

      - layout: left #pid-39/2-14 | Berkeley/Stanford Parser Evaluation and Analysis
        title: Berkeley/Stanford Parser Evaluation and Analysis
        link: https://github.com/rohanredtj/1_NLP_Parser/blob/master/berkely_stanford_parser_evalb.ipynb
        link_text: Project Code ðŸ”—
        
        description: |
          
          Implemented and evaluated the <mark>performance</mark> of the Berkeley and Stanford parsers on the Wall Street Journal <mark>corpus</mark>. Developed custom Python scripts to calculate parsing <mark>accuracy</mark> metrics like precision, recall, and F1 score. Conducted <mark>comparative analysis</mark> of parser outputs using the EVALB scoring program and visualized results. <a href="https://drive.google.com/file/d/1oRSf3-IbD_xBKeBPdRax2mrIqmGJk9RD" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Python, NLTK, Pandas, Matplotlib, Berkeley Parser, Stanford Parser, EVALB Evaluation


  - title: Data Analytics Projects
    layout: list
    content:


      - layout: left #pid-11/3-2 | Reverse ETL based Customer Data Integration Platform with Metabase
        title: Reverse ETL based Customer Data Integration Platform with Metabase
        link: /#
        link_text: Proprietary Work
        
        description: |
          
          Engineered a centralized reverse ETL customer data store, seamlessly <mark>integrating</mark> Hubspot, Klaviyo, and website tracking sources. Implemented robust <mark>data synchronization</mark> and conflict resolution mechanisms to ensure data integrity across platforms. Leveraged dbt for efficient data transformation and SQL for complex queries, creating a comprehensive, <mark>unified view</mark> of customer data, and visualization based on it in Metabase. This solution streamlined customer analytics and enabled more <mark>targeted marketing</mark> strategies. <a href="https://drive.google.com/file/d/1fCHU4JaJEkwM7tWxbhdFJL7jMWYKhC-j" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** DBT, Metabase, SQL, BigQuery, Airbyte, RudderStack, Klaviyo, Hubspot

          ---

      - layout: left #pid-13/3-6 | Superset Dashboard for Process Scoring System
        title: Superset Dashboard for Process Scoring System
        link: https://github.com/rohanredtj/1_NLP_Parser/blob/master/berkely_stanford_parser_evalb.ipynb
        link_text: Proprietary Work
        
        description: |
          
          Developed a scoring dashboard using Apache Superset to analyze and <mark>visualize performance</mark> metrics across multiple dimensions. Implemented time-based reporting, <mark>weighted scoring</mark>, and user comparison features. Integrated with MySQL database and explored materialized views for efficient data handling. Investigated API integrations and webhook implementations to enable <mark>real-time</mark> dashboard updates and notifications. <a href="https://drive.google.com/file/d/16LN9N7Y3FpOVzYEe3CpPhnHyJpIfk8v8" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Apache Superset, MySQL, Flask, Jinja, Docker, Git, RESTful APIs, Webhooks

          ---

      - layout: left #pid-4/3-7 | Sales Performance Tracking Dashboard using Looker
        title: Sales Performance Tracking Dashboard using Looker
        link: https://lookerstudio.google.com/reporting/2bb9d789-cfc0-408c-8e6c-ff4a2a1e7917
        link_text: Proprietary Work (Sample Dashboard)
        
        description: |
          
          Developed a comprehensive sales tracking board to <mark>monitor</mark> and analyze <mark>sales associate</mark> performance. The dashboard features KPI tracking, scoreboard metrics, and visual representations of sales data. It allows for time-based <mark>filtering</mark> and provides a clear ranking system for sales associates. This tool enhances <mark>performance visibility</mark> and facilitates data-driven decision making in the sales department. <a href="https://drive.google.com/file/d/1gARfu23bbhtUQnqaYZ_AZJbY3sqmvqIF" target="_blank" rel="noopener noreferrer" style="color: inherit;"> <i class="far fa-file-alt"></i> </a>
          
          **Technologies:** Looker Studio, SQL, Google Sheets


footer_show_references: false


remote_theme: sproogen/resume-theme


sass:
  sass_dir: _sass
  style: compressed


plugins:
 - jekyll-seo-tag
